{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 只做单模型，其他的内容，等等再说，现在把单模型的表现提升上去再说,这份code的目标只是为了提升模型的分类效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "import collections\n",
    "import time\n",
    "import random\n",
    "\n",
    "import model_ml as mm\n",
    "import feat_engineering as fe\n",
    "import feat_selection as fs\n",
    "import model_tunning as mt\n",
    "from param_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(config.original_train_data_path)\n",
    "dfPred = pd.read_csv(config.original_pred_data_path)\n",
    "predictors = dfPred.columns.tolist()[4:]\n",
    "check_missing = ['PartI_1','PartII_1','PartIII_1','PartIV_1','PartV_1','PartVI_1']\n",
    "\n",
    "###清理异常Y值\n",
    "#异常大值\n",
    "dfTrain = dfTrain.loc[dfTrain['Y']<dfTrain['Y'].max()]\n",
    "\n",
    "#性别空\n",
    "dfTrain = dfTrain.loc[~dfTrain['sex'].isnull()]\n",
    "\n",
    "dfTrain = dfTrain.reset_index(drop=True)\n",
    "\n",
    "saveY = dfTrain['Y'].tolist()\n",
    "\n",
    "dfTrain.loc[dfTrain['Y']>dfTrain['Y'].quantile(0.9),'Y'] = 1\n",
    "dfTrain.loc[dfTrain['Y']!=1,'Y'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FeatAll(train,pred,rankMinus=False,missing=False,missing_step2=False):\n",
    "    dfAll = pd.concat([train,pred])\n",
    "    dfAll = dfAll.reset_index(drop=True)\n",
    "    dfAll['date'] = (pd.to_datetime(dfAll['date']) - parse('2017-10-09')).dt.days\n",
    "    \n",
    "    ###RF填补缺失值\n",
    "    if missing:\n",
    "        dfAll = fe.fillna_RF(dfAll,predictors,True)\n",
    "\n",
    "    \n",
    "    ###尝试处理异常值\n",
    "    '''for var in predictors:\n",
    "        dfAll.loc[dfAll[var]>=dfAll[var].quantile(0.99)*3,var] = dfAll[var].quantile(0.99)*3'''\n",
    "        #dfAll.loc[dfAll[var]>=df[var].quantile(0.99)*1.5,var] = np.nan\n",
    "    ###根据年龄性别去做分类，鉴别不同人的百分比\n",
    "    dfAll['ageBin'] = 0\n",
    "    ageBin = [20,30,40,50,60]\n",
    "    for i in range(len(ageBin)):\n",
    "        dfAll.loc[dfAll['age']>ageBin[i],'ageBin'] = i+1\n",
    "    dfAll['sexAge'] = dfAll[['sex','ageBin']].apply(lambda x: x[1]*2+x[0])\n",
    "    dfAllPcentBySexAge = fe.pcent_by_other_col(dfAll,{'sex':predictors,'ageBin':predictors,'sexAge':predictors},['ID'])\n",
    "    del dfAll['age']\n",
    "    del dfAll['sexAge']\n",
    "    if rankMinus:\n",
    "        try:\n",
    "            for i in ['_sex_','_ageBin_','_sexAge']:\n",
    "                dfrankMinusTmp = pd.read_csv('../../Cache/rankMinus%s.csv'%i[:-1])\n",
    "                if i == '_sex_':\n",
    "                    dfrankMinus = dfrankMinusTmp.copy()\n",
    "                else:\n",
    "                    dfrankMinus = dfrankMinus.merge(dfrankMinusTmp,'inner','ID')\n",
    "        except:\n",
    "            for i in ['_sex_','_ageBin_','_sexAge']:\n",
    "                varList = [var for var in dfAllPcentBySexAge.columns if i in var]\n",
    "                dfrankMinusTmp = fe.var_minus(dfAllPcentBySexAge,varList,['ID'],0)\n",
    "                dfrankMinusTmp.to_csv('../../Cache/rankMinus%s.csv'%i[:-1],index=False)\n",
    "                if i == '_sex_':\n",
    "                    dfrankMinus = dfrankMinusTmp.copy()\n",
    "                else:\n",
    "                    dfrankMinus = dfrankMinus.merge(dfrankMinusTmp,'inner','ID')  \n",
    "\n",
    "    \n",
    "    ###目前不想使用日期，觉得用处不大\n",
    "    del dfAll['date']\n",
    "\n",
    "    #for minus in\n",
    "    \n",
    "    for plus in [['PartII_1','PartII_2'],['PartIII_1','PartIII_2','PartIII_3']]:\n",
    "        tmpVar =plus[0]\n",
    "        tmpValue = dfAll[plus[0]].values\n",
    "        for var in plus[1:]:\n",
    "            tmpVar = tmpVar +'_plus_' + var\n",
    "            tmpValue = tmpValue + dfAll[var].values\n",
    "        dfAll[tmpVar] = tmpValue\n",
    "    \n",
    "    dfAll['PartI_9'] = dfAll['PartI_5']-dfAll['PartI_6']-dfAll['PartI_7']\n",
    "    dfAll['PartII_5'] = dfAll['PartII_2']-dfAll['PartII_3']-dfAll['PartII_4']\n",
    "    \n",
    "    for ratio in [['PartII_1','PartII_2'],['PartI_6','PartI_5'],['PartI_7','PartI_5'],['PartII_3','PartII_2'],['PartII_4','PartII_2'],['PartV_2','PartV_1'],['PartII_1','PartII_2']]:\n",
    "        dfAll[ratio[0]+'_divided_'+ratio[1]] = dfAll[ratio[0]]/dfAll[ratio[1]]\n",
    "        \n",
    "    for multiply in [['PartI_1','PartI_5'],['PartI_2','PartI_5'],['PartI_3','PartI_5'],['PartI_4','PartI_5'],['PartVI_1','PartVI_2'],['PartV_2','PartV_5'],['PartV_2','PartV_7'],['PartV_1','PartV_9'],['PartV_1','PartV_10'],['PartV_1','PartV_11'],['PartV_1','PartV_12'],['PartV_1','PartV_13']]:\n",
    "        dfAll[multiply[0]+'_multiply_'+multiply[1]] = dfAll[multiply[0]]*dfAll[multiply[1]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dfAll = dfAll.merge(dfAllPcentBySexAge,'inner','ID')\n",
    "    except:\n",
    "        print('No Pcent by sex and age')\n",
    "        \n",
    "    try:\n",
    "        dfAll = dfAll.merge(dfrankMinus,'inner','ID')\n",
    "    except:\n",
    "        print('No Rank Minus')    \n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    ###填补缺失值\n",
    "    if missing_step2:\n",
    "        dfAll =dfAll.fillna(dfAll.median())\n",
    "    \n",
    "    dfTrain = dfAll.loc[dfAll['ID'].isin(train['ID'])]\n",
    "    dfPred = dfAll.loc[dfAll['ID'].isin(pred['ID'])]\n",
    "    \n",
    "    return dfTrain,dfPred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "dfTrain,dfPred = FeatAll(dfTrain,dfPred,True,True,True)\n",
    "predictors = dfPred.columns.tolist()\n",
    "predictors.remove('ID')\n",
    "predictors.remove('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2170"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorsRF =[]\n",
    "for i in range(2):\n",
    "    t1 = datetime.datetime.now()\n",
    "    predictorsRF += fs.RF_selection(dfTrain,predictors,int(random.random()*10000))[:1000]\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(\"finish %d, use %d seconds\"%(i,(t2-t1).seconds))\n",
    "count = collections.Counter(predictorsRF)\n",
    "dfpredictorsRF = pd.DataFrame(count,index=['count']).T\n",
    "dfpredictorsRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testResult = dfTrain[['ID','Y']]\n",
    "predResult = dfPred[['ID','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "early_stop=50\n",
    "params = {'max_depth':5, 'eta':0.01, 'silent':0,'objective':'binary:logistic','lambda':1,'subsample':0.8,'colsample_bytree':0.8,'eval_metric':'logloss'}\n",
    "repeatRound =10\n",
    "selectNum = 150\n",
    "modelPredictors = predictors[:10]\n",
    "for i in range(repeatRound):\n",
    "    test_result,result,imp = mm.xgb_kfold(dfTrain,dfPred,tmpPredictor,n_splits,early_stop = early_stop,params=params,seed=int(random.random()*10000))\n",
    "    for j in range(1,n_splits+1):\n",
    "        imp['imp_fold%d'%j] = imp['imp_fold%d'%j]/imp['imp_fold%d'%j].sum()\n",
    "    imp['sum_imp%d'%i] = imp[['imp_fold%d'%k for k in range(1,n_splits+1)]].sum(axis=1)\n",
    "    if i ==0:\n",
    "        importance = imp[['variable','sum_imp%d'%i]]\n",
    "    else:\n",
    "        importance = importance.merge(imp[['variable','sum_imp%d'%i]],'inner','variable')\n",
    "\n",
    "importance['sum_total'] = importance[['sum_imp%d'%k for k in range(repeatRound)]].sum(axis=1)\n",
    "tmpPredictor = importance.sort_values('sum_total',ascending=False)['variable'].values.tolist()[:selectNum] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###xgb\n",
    "n_splits=5\n",
    "early_stop=50\n",
    "repeatRound =2\n",
    "selectNum = 150\n",
    "modelPredictors = tmpPredictor.copy()\n",
    "for i in range(repeatRound):\n",
    "    test_result,result,imp = mm.xgb_kfold(dfTrain,dfPred,modelPredictors,n_splits,early_stop = early_stop,params=params)\n",
    "    result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "    if i ==0:\n",
    "        tmpTest_result = test_result[['ID','score']]\n",
    "        tmpResult = result[['ID','score']]\n",
    "    else:\n",
    "        tmpTest_result = tmpTest_result.merge(test_result[['ID','score']],'inner','ID')\n",
    "        tmpResult = tmpResult.merge(result[['ID','score']],'inner','ID')\n",
    "    tmpTest_result.rename(columns={'score':'score_%d'%i},inplace=True)\n",
    "    tmpResult.rename(columns={'score':'score_%d'%i},inplace=True)\n",
    "testResult['cateScoreXGB'] = tmpTest_result[['score_%d'%i for i in range(repeatRound)]].mean(axis=1).values\n",
    "predResult['cateScoreXGB'] = tmpResult[['score_%d'%i for i in range(repeatRound)]].mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Logloss: 0.309653690499\n",
      "Test Logloss: 0.301790137208\n",
      "Test Logloss: 0.30573066069\n",
      "Test Logloss: 0.294166023361\n",
      "Test Logloss: 0.300390259294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Logloss: 0.297249523045\n",
      "Test Logloss: 0.293567831701\n",
      "Test Logloss: 0.305804456279\n",
      "Test Logloss: 0.300222917516\n",
      "Test Logloss: 0.300887310003\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testResult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-922ee41baa57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtmpTest_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'score_%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtmpResult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'score_%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtestResult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cateScoreRF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmpTest_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score_%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeatRound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mpredResult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cateScoreRF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmpResult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score_%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeatRound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testResult' is not defined"
     ]
    }
   ],
   "source": [
    "###RF\n",
    "n_splits=5\n",
    "early_stop=50\n",
    "repeatRound =2\n",
    "selectNum = 150\n",
    "modelPredictors = predictors[:10]\n",
    "for i in range(repeatRound):\n",
    "    test_result,result,imp = mm.rf_kfold(dfTrain,dfPred,modelPredictors,n_splits,seed=int(random.random()*10000))\n",
    "    result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "    if i ==0:\n",
    "        tmpTest_result = test_result[['ID','score']]\n",
    "        tmpResult = result[['ID','score']]\n",
    "    else:\n",
    "        tmpTest_result = tmpTest_result.merge(test_result[['ID','score']],'inner','ID')\n",
    "        tmpResult = tmpResult.merge(result[['ID','score']],'inner','ID')\n",
    "    tmpTest_result.rename(columns={'score':'score_%d'%i},inplace=True)\n",
    "    tmpResult.rename(columns={'score':'score_%d'%i},inplace=True)\n",
    "testResult['cateScoreRF'] = tmpTest_result[['score_%d'%i for i in range(repeatRound)]].mean(axis=1).values\n",
    "predResult['cateScoreRF'] = tmpResult[['score_%d'%i for i in range(repeatRound)]].mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###catboost\n",
    "n_splits=5\n",
    "early_stop=50\n",
    "repeatRound =2\n",
    "selectNum = 150\n",
    "modelPredictors = predictors[:10]\n",
    "for i in range(repeatRound):\n",
    "    test_result,result,imp = mm.catboost_kfold(dfTrain,dfPred,modelPredictors,n_splits,early_stop=50,seed=int(random.random()*10000))\n",
    "    result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "    if i ==0:\n",
    "        tmpTest_result = test_result[['ID','score']]\n",
    "        tmpResult = result[['ID','score']]\n",
    "    else:\n",
    "        tmpTest_result = tmpTest_result.merge(test_result[['ID','score']],'inner','ID')\n",
    "        tmpResult = tmpResult.merge(result[['ID','score']],'inner','ID')\n",
    "    tmpTest_result.rename(columns={'score':'score_%d'%i},inplace=True)\n",
    "    tmpResult.rename(columns={'score':'score_%d'%i},inplace=True)\n",
    "testResult['cateScoreCat'] = tmpTest_result[['score_%d'%i for i in range(repeatRound)]].mean(axis=1).values\n",
    "predResult['cateScoreCat'] = tmpResult[['score_%d'%i for i in range(repeatRound)]].mean(axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selectNum = 150\n",
    "for i in range(1,n_splits+1):\n",
    "    imp['imp_fold%d'%i] = imp['imp_fold%d'%i]/imp['imp_fold%d'%i].sum()\n",
    "imp['sum_imp'] = imp[['imp_fold%d'%i for i in range(1,n_splits+1)]].sum(axis=1)\n",
    "\n",
    "tmpPredictor = imp.sort_values('sum_imp',ascending=False)['variable'].values.tolist()[:selectNum]\n",
    "imp.sort_values('sum_imp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result,result,imp_selected = mm.xgb_kfold(dfTrain,dfPred,tmpPredictor,n_splits,early_stop = early_stop,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mt.evaluate_performance(test_result['target'],test_result['score'])\n",
    "imp.sort_values('sum_imp',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##将分类打分放入原始数据\n",
    "dfTrain['scoreBinary'] = test_result['score']\n",
    "result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "dfPred['scoreBinary'] = result['score'].tolist()\n",
    "\n",
    "predictorReg = predictors.copy()\n",
    "predictorReg.append('scoreBinary')\n",
    "\n",
    "dfTrain['Y'] = saveY\n",
    "\n",
    "##将分数以rank形式保存一份\n",
    "'''dfTrain['scoreBinaryPcent'] = dfTrain['scoreBinary'].rank()/float(dfTrain.shape[0])\n",
    "dfPred['scoreBinaryPcent'] = dfPred['scoreBinary'].rank()/float(dfPred.shape[0])\n",
    "predictorReg.append('scoreBinaryPcent')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dfTrain['scoreBinary'].mean())\n",
    "print(dfTrain['scoreBinary'].max())\n",
    "print(dfTrain['scoreBinary'].min())\n",
    "print('--------------')\n",
    "print(dfPred['scoreBinary'].mean())\n",
    "print(dfPred['scoreBinary'].max())\n",
    "print(dfPred['scoreBinary'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictorsRF = fs.RF_selection(dfTrain,predictorReg)\n",
    "modelPredictors = predictorsRF[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "early_stop=50\n",
    "params = {'max_depth':5, 'eta':0.01, 'silent':0,'objective':'reg:linear','lambda':1,'subsample':0.8,'colsample_bytree':0.8}\n",
    "test_result,result,imp = mm.xgb_kfold(dfTrain,dfPred,modelPredictors,n_splits,early_stop=early_stop,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selectNum = 100\n",
    "for i in range(1,n_splits+1):\n",
    "    imp['imp_fold%d'%i] = imp['imp_fold%d'%i]/imp['imp_fold%d'%i].sum()\n",
    "imp['sum_imp'] = imp[['imp_fold%d'%i for i in range(1,n_splits+1)]].sum(axis=1)\n",
    "\n",
    "tmpPredictor = imp.sort_values('sum_imp',ascending=False)['variable'].values.tolist()[0:selectNum+1]\n",
    "imp.sort_values('sum_imp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result,result,imp_selected = mm.xgb_kfold(dfTrain,dfPred,tmpPredictor,n_splits,early_stop=early_stop,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,n_splits+1):\n",
    "    imp_selected['imp_fold%d'%i] = imp_selected['imp_fold%d'%i]/imp_selected['imp_fold%d'%i].sum()\n",
    "imp_selected['sum_imp'] = imp_selected[['imp_fold%d'%i for i in range(1,n_splits+1)]].sum(axis=1)\n",
    "imp_selected.sort_values('sum_imp',ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "print((result['score']>6.8).sum())\n",
    "print(result['score'].min())\n",
    "print(result['score'].max())\n",
    "print(result['score'].mean())\n",
    "print(result['score'].median())\n",
    "print(\"-------------------------\")\n",
    "print(result.iloc[938,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "other_note ='_classfier_first'\n",
    "result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "submit = result[['ID','score']]\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "result.to_csv('../../Submission/result/result_%s'%today+other_note+'.csv',index=False)\n",
    "submit['score'].to_csv('../../Submission/submit_%s'%today+other_note+'.csv',header=False,index=False)\n",
    "test_result.to_csv('../../Submission/test/test_result_%s'%today+other_note+'.csv',index=False)\n",
    "imp.to_csv('../../Submission/imp/importance_%s'%today+other_note+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
